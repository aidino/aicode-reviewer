import re
import tempfile
import shutil
import os
from git import Repo, GitCommandError
from sqlalchemy.orm import Session
from ..models import Project
from datetime import datetime, timezone
from typing import Tuple, List
import requests
import logging

# Import new services
from .token_manager import TokenManager
from .repository_cache_service import RepositoryCacheService

logger = logging.getLogger(__name__)

def detect_repository_type(repo_url: str) -> Tuple[str, str, str]:
    """
    X√°c ƒë·ªãnh lo·∫°i repository (github, gitlab, bitbucket) v√† tr·∫£ v·ªÅ (type, owner, repo_name)
    """
    # GitHub
    m = re.match(r"https?://github.com/([^/]+)/([^/.]+)", repo_url)
    if m:
        return ("github", m.group(1), m.group(2))
    # GitLab
    m = re.match(r"https?://gitlab.com/([^/]+)/([^/.]+)", repo_url)
    if m:
        return ("gitlab", m.group(1), m.group(2))
    # Bitbucket
    m = re.match(r"https?://bitbucket.org/([^/]+)/([^/.]+)", repo_url)
    if m:
        return ("bitbucket", m.group(1), m.group(2))
    raise ValueError("Kh√¥ng h·ªó tr·ª£ repo_url n√†y ho·∫∑c URL kh√¥ng h·ª£p l·ªá")

def clone_repository(repo_url: str, use_ssh: bool = False, access_token: str = None) -> str:
    """
    üö® DEPRECATED: Use RepositoryCacheService.get_or_clone_repository() instead.
    Clone repo v·ªÅ th∆∞ m·ª•c t·∫°m, tr·∫£ v·ªÅ path. N·∫øu use_ssh=True, chuy·ªÉn sang d·∫°ng SSH URL.
    """
    logger.warning("üö® Using deprecated clone_repository function. Consider using RepositoryCacheService.")
    
    tmp_dir = tempfile.mkdtemp(prefix="repo_clone_")
    clone_url = repo_url
    if access_token:
        # Clone qua HTTPS v·ªõi token (PAT) - GitHub format
        # Format: https://token@github.com/owner/repo.git
        if "github.com" in repo_url:
            clone_url = repo_url.replace("https://", f"https://{access_token}@")
            if not clone_url.endswith('.git'):
                clone_url += '.git'
        else:
            # For other platforms, use older format
            clone_url = repo_url.replace("https://", f"https://{access_token}:x-oauth-basic@")
    elif use_ssh:
        m = re.match(r"https?://github.com/([^/]+)/([^/.]+)", repo_url)
        if m:
            owner, repo = m.group(1), m.group(2)
            clone_url = f"git@github.com:{owner}/{repo}.git"
    
    print(f"üîÑ Attempting to clone: {repo_url}")
    print(f"üîë Using access token: {'Yes' if access_token else 'No'}")
    print(f"üåê Clone URL format: {clone_url[:50]}...")  # Only show first 50 chars for security
    
    try:
        Repo.clone_from(clone_url, tmp_dir)
        print(f"‚úÖ Clone successful to: {tmp_dir}")
        return tmp_dir
    except GitCommandError as e:
        print(f"‚ùå Clone failed: {e}")
        shutil.rmtree(tmp_dir)
        
        # Parse error message ƒë·ªÉ cung c·∫•p th√¥ng b√°o c·ª• th·ªÉ
        error_str = str(e).lower()
        if "403" in error_str and "write access to repository not granted" in error_str:
            raise RuntimeError("Permission denied: Token kh√¥ng c√≥ quy·ªÅn truy c·∫≠p repository n√†y. H√£y ki·ªÉm tra: 1) Token c√≥ scope 'repo' kh√¥ng? 2) Token c√≥ expired kh√¥ng? 3) User s·ªü h·ªØu token c√≥ quy·ªÅn truy c·∫≠p repo kh√¥ng?")
        elif "404" in error_str or "repository not found" in error_str:
            raise RuntimeError("Repository not found: URL kh√¥ng ƒë√∫ng ho·∫∑c repository kh√¥ng t·ªìn t·∫°i")
        elif "authentication failed" in error_str or "401" in error_str:
            raise RuntimeError("Authentication failed: Token kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ expired")
        elif "fatal: could not read username" in error_str:
            raise RuntimeError("Authentication required: Repository l√† private, c·∫ßn Personal Access Token")
        else:
            raise RuntimeError(f"Clone repo th·∫•t b·∫°i: {e}")

def add_repository_with_metadata(db: Session, repo_url: str, user_id: int, access_token: str = None) -> dict:
    """
    üÜï Smart Repository Management:
    Th√™m repository m·ªõi v·ªõi smart caching v√† secure token storage.
    - L∆∞u PAT token ƒë∆∞·ª£c encrypt an to√†n
    - Cache source code v·ªõi intelligent sync
    - Update metadata khi repository ƒë√£ t·ªìn t·∫°i cho user n√†y
    """
    repo_url = str(repo_url)  # ƒê·∫£m b·∫£o lu√¥n l√† string (fix l·ªói HttpUrl)
    
    repo_type, owner, repo_name = detect_repository_type(repo_url)
    
    # Initialize services
    token_manager = TokenManager()
    cache_service = RepositoryCacheService()
    
    # Check if repository already exists FOR THIS USER
    existing_project = db.query(Project).filter(
        Project.url == repo_url,
        Project.owner_id == user_id
    ).first()
    
    repo_path = None
    try:
        if existing_project:
            logger.info(f"üìù Repository already exists for user {user_id}: {existing_project.name}")
            
            # Update/store token if provided
            if access_token:
                token_manager.store_token(existing_project, access_token)
                logger.info(f"üîë Updated token for existing repository: {existing_project.name}")
            
            # Try to get repository from cache or clone with stored token
            try:
                repo_path = cache_service.get_or_clone_repository(existing_project, db)
                logger.info(f"‚úÖ Got repository from cache: {repo_path}")
            except Exception as cache_error:
                logger.warning(f"Cache failed, using temporary clone: {cache_error}")
                # Fallback to temporary clone for metadata only
                stored_token = token_manager.get_token(existing_project)
                repo_path = clone_repository(repo_url, access_token=stored_token or access_token)
        else:
            logger.info(f"‚ûï Adding new repository for user {user_id}: {repo_name}")
            
            # For new repositories, use temporary clone first to get metadata
            repo_path = clone_repository(repo_url, access_token=access_token)
        
        # 2. L·∫•y metadata
        if repo_type == "github":
            try:
                meta = fetch_github_metadata(owner, repo_name)
            except Exception:
                meta = parse_local_metadata(repo_path)
        else:
            meta = parse_local_metadata(repo_path)
        
        now = datetime.now(timezone.utc)
        
        if existing_project:
            # 3a. Update existing repository metadata
            logger.info(f"üìù Updating metadata for: {existing_project.name}")
            existing_project.name = meta["name"]
            existing_project.description = meta["description"]
            existing_project.avatar_url = meta["avatar_url"]
            existing_project.language = meta["language"]
            existing_project.default_branch = meta["default_branch"]
            existing_project.is_private = meta["is_private"]
            existing_project.stars = meta["stars"]
            existing_project.forks = meta["forks"]
            existing_project.last_synced_at = now
            existing_project.updated_at = now
            
            db.commit()
            db.refresh(existing_project)
            
            # Set up smart cache for future use if not already cached
            if not existing_project.is_cache_valid:
                try:
                    cache_path = cache_service.get_or_clone_repository(existing_project, db)
                    logger.info(f"üóÇÔ∏è Set up cache for repository: {cache_path}")
                except Exception as e:
                    logger.warning(f"Could not set up cache: {e}")
            
            # Return updated project data
            return {
                "id": existing_project.id,
                "name": existing_project.name,
                "url": existing_project.url,
                "description": existing_project.description,
                "avatar_url": existing_project.avatar_url,
                "language": existing_project.language,
                "default_branch": existing_project.default_branch,
                "is_private": existing_project.is_private,
                "stars": existing_project.stars,
                "forks": existing_project.forks,
                "owner_id": existing_project.owner_id,
                "created_at": existing_project.created_at,
                "updated_at": existing_project.updated_at,
                "last_synced_at": existing_project.last_synced_at,
                "_updated": True  # Flag to indicate this was an update
            }
        else:
            # 3b. Create new repository
            logger.info(f"‚ûï Creating new repository: {meta['name']}")
            project = Project(
                name=meta["name"],
                url=repo_url,
                description=meta["description"],
                avatar_url=meta["avatar_url"],
                language=meta["language"],
                default_branch=meta["default_branch"],
                is_private=meta["is_private"],
                stars=meta["stars"],
                forks=meta["forks"],
                last_synced_at=now,
                created_at=now,
                updated_at=now,
                owner_id=user_id,
            )
            db.add(project)
            db.commit()
            db.refresh(project)
            
            # Store token if provided
            if access_token:
                token_manager.store_token(project, access_token)
                db.commit()
                logger.info(f"üîë Stored token for new repository: {project.name}")
            
            # Set up smart cache
            try:
                cache_path = cache_service.get_or_clone_repository(project, db)
                logger.info(f"üóÇÔ∏è Set up cache for new repository: {cache_path}")
            except Exception as e:
                logger.warning(f"Could not set up cache for new repository: {e}")
            
            # Return new project data
            return {
                "id": project.id,
                "name": project.name,
                "url": project.url,
                "description": project.description,
                "avatar_url": project.avatar_url,
                "language": project.language,
                "default_branch": project.default_branch,
                "is_private": project.is_private,
                "stars": project.stars,
                "forks": project.forks,
                "owner_id": project.owner_id,
                "created_at": project.created_at,
                "updated_at": project.updated_at,
                "last_synced_at": project.last_synced_at,
                "_created": True  # Flag to indicate this was a new creation
            }
    finally:
        # Clean up temporary directory if it was used
        if repo_path and repo_path.startswith(tempfile.gettempdir()):
            if os.path.exists(repo_path):
                shutil.rmtree(repo_path)
                logger.debug(f"üóëÔ∏è Cleaned up temporary directory: {repo_path}")

def get_repository_for_scan(project: Project, db: Session) -> str:
    """
    üÜï Get repository path for scanning with smart cache.
    Returns cached path if available, otherwise clones fresh.
    
    Args:
        project: Project instance
        db: Database session
        
    Returns:
        str: Path to repository directory
    """
    cache_service = RepositoryCacheService()
    
    try:
        repo_path = cache_service.get_or_clone_repository(project, db)
        logger.info(f"üîç Repository ready for scan: {project.name} -> {repo_path}")
        return repo_path
    except Exception as e:
        logger.error(f"Failed to get repository for scan: {project.name}: {e}")
        raise RuntimeError(f"Cannot prepare repository for scan: {str(e)}")

def fetch_github_metadata(owner: str, repo: str) -> dict:
    """
    L·∫•y metadata repo t·ª´ GitHub API (public info).
    """
    url = f"https://api.github.com/repos/{owner}/{repo}"
    resp = requests.get(url)
    if resp.status_code == 200:
        data = resp.json()
        return {
            "name": data.get("name"),
            "description": data.get("description"),
            "avatar_url": data.get("owner", {}).get("avatar_url"),
            "language": data.get("language"),
            "default_branch": data.get("default_branch"),
            "is_private": data.get("private", False),
            "stars": data.get("stargazers_count", 0),
            "forks": data.get("forks_count", 0),
        }
    else:
        raise RuntimeError(f"Kh√¥ng l·∫•y ƒë∆∞·ª£c metadata t·ª´ GitHub API: {resp.status_code}")

def parse_local_metadata(repo_path: str) -> dict:
    """
    Parse metadata c∆° b·∫£n t·ª´ local repo (README, .git/config).
    """
    name = os.path.basename(repo_path)
    description = None
    readme_path = os.path.join(repo_path, "README.md")
    if os.path.exists(readme_path):
        with open(readme_path, "r", encoding="utf-8") as f:
            description = f.readline().strip()
    # TODO: Parse th√™m .git/config n·∫øu c·∫ßn
    return {
        "name": name,
        "description": description,
        "avatar_url": None,
        "language": None,
        "default_branch": None,
        "is_private": False,
        "stars": 0,
        "forks": 0,
    }

def get_user_repositories(db: Session, user_id: int) -> List[Project]:
    """
    L·∫•y danh s√°ch repositories c·ªßa user t·ª´ database.
    
    Args:
        db: Database session
        user_id: ID c·ªßa user
        
    Returns:
        List[Project]: Danh s√°ch repositories c·ªßa user
    """
    logger.info(f"üìã Getting repositories for user {user_id}")
    
    repositories = db.query(Project).filter(
        Project.owner_id == user_id
    ).order_by(Project.updated_at.desc()).all()
    
    logger.info(f"‚úÖ Found {len(repositories)} repositories for user {user_id}")
    return repositories 